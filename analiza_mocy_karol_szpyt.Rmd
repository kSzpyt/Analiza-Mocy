---
title: "Analiza Mocy"
author: "Karol Szpyt"
date: "7 listopada 2018"
output: html_document
---
```{r include=FALSE}
now <- Sys.time()
```
###Pakiety  
Poniżej wymienione są pakiety, które zostały użyte w tym badaniu.
```{r pakiety, message=FALSE, warning=FALSE}
library(dplyr)
library(tidyr)
library(nortest)
library(tseries)
library(ggplot2)
library(reshape2)
library(tidyverse)
library(kableExtra)
library(Hmisc)
```  

###Wstęp  
Praca ta ma za zadanie pokazać jak zmieniają się moce testów w zależności od kolejno: 

* **długości** próby- 10, 20, 50, 70, 100, 200
* **rozkładu** próby- t studenta, wykładniczy oraz jednostajny  

W badaniu użyte zostały następujące testy:

 * test Shapiro Wilka- test bazuje na wykresach typu kwantyl-kwantyl
 * test Lillieforsa- test bada różnice między dystrybuantą empiryczną a teoretyczną. Jest to modyfikacja testu Kołmogorowa-Smirnowa. W przeciwiństwie do KS testu nie potrzebna jest informacja o śreniej oraz odchyleniu standardowym badanej próby. 
 * test Jarque- Bera
 * test Pearson'a
 * test Andersona-Darlinga- test bazujący na różnicach między dystrybuantami
 
Badanie przeprowadzone zostanie poprzez empiryczne wyznaczenie mocy poszczególnych testów. Wyniki następnie zostaną porównane.  
```{r include=FALSE}
gen <- function(y)
{
  dane <- lapply(y, function(x)
  {
    list("ts" = rt(x, 2), 
         "unif" = runif(x, -1, 1), 
         "exp" = rexp(x, 1)
    )
    
  }) 
  return(dane)
}
```

###Hipoteza  
####Dystrybuanta
```{r echo=FALSE, fig.align='center'}
z <- 100
x <- seq(from=-10, to=10, by=.1)
y <- pnorm(x)
set.seed(110)
dat <- gen(z)
par(mfrow = c(2, 2))
plot(ecdf(rnorm(z)), main = "norm")
lines(x, y, type='l', col = "red", lwd = 4)
plot(ecdf(dat[[1]][[1]]), main = "t-studnet")
lines(x, y, type='l', col = "red", lwd = 4)
plot(ecdf(dat[[1]][[2]]), main = "unif")
lines(x, y, type='l', col = "red", lwd = 4)
plot(ecdf(dat[[1]][[3]]), main = "exp")
lines(x, y, type='l', col = "red", lwd = 4)
```  
Czerwoną linią zaznaczona jest teoretyczna dystybuanta rozkładu normalnego. Na czarno widnieją dystybuanty wyliczone bezpośrednio z próby (100 elementowej) dzięki funkcji **ecdf()** z pakietu Hmisc. 
 
####Gęstość
```{r echo=FALSE, fig.align='center'}
set.seed(110)
z <- 100
dat <- gen(z)
par(mfrow = c(2, 2))
plot(density(rnorm(z)), main = "norm")
lines(density(rnorm(10000000)), main = "norm", col = "red", lwd = 4)
plot(density(dat[[1]][[1]]), main = "t-studnet")
lines(density(rnorm(10000000)), main = "norm", col = "red", lwd = 4)
plot(density(dat[[1]][[2]]), main = "unif")
lines(density(rnorm(10000000)), main = "norm", col = "red", lwd = 4)
plot(density(dat[[1]][[3]]), main = "exp")
lines(density(rnorm(10000000)), main = "norm", col = "red", lwd = 4)
```
Podobna sytuacja co wyżej, z tym że dotycząca gęstości.  
  
Po przyjrzeniu się powyższym wykresom można będzie sie spodziewać, że testy najczęściej mylić się będą przy badaniu próby pochodzącej z rozkładu t-studenta co skutkować powinno zmniejszoną mocą testu. 

###Badanie  

Liczba symulacji ustawiona została na 1000 powtórzeń, a poziom istotności na 5%.
```{r parametry}
len <- c(10, 20, 50, 70, 100, 200)
sym <- 10
alpha <- 0.05
```  
Funckja losująca próbę (jednocześnie ze wszystkich trzech rozkładów):
```{r losowanie, eval = FALSE}
gen <- function(y)
{
  dane <- lapply(y, function(x)
  {
    list("ts" = rt(x, 2), 
         "unif" = runif(x, -1, 1), 
         "exp" = rexp(x, 1)
    )
    
  }) 
  return(dane)
}
```
Wykorzystana następnie w głównej części pracy, czyli pętli obliczającej p-value ze wszystkich testów
```{r core}
df <- data.frame()
for (a in len)
{
  for (b in 1:sym) 
  {
    data <- gen(a)
    pvalues <- lapply(data[[1]], function(x)
    {
      list(
           "sw" = shapiro.test(x)$p.value,
           "jb" = jarque.bera.test(x)$p.value,
           "li" = lillie.test(x)$p.value,
           "chi" = pearson.test(x)$p.value,
           "ad" = ad.test(x)$p.value)
    })
    df <- rbind(df, c(as.data.frame(pvalues), "length" = a))
    
  }
}
```
  
```{r kosmetyka, include=FALSE}
df_pomoc <- df

df <- cbind(df[,-length(df)] < alpha, "length" = df[,length(df)])
df <- as_tibble(df)
df2 <- df %>%
  group_by(length) %>%
  summarise_all(funs(mean))

mali <- list()
for (c in 1:length(len))
  {
  m <- matrix(df2[c,-1], ncol = 5, byrow = TRUE)
  m <- as.data.frame(m)
  colnames(m) <- c("sw", "jb", "li", "chi", "ad")
  rownames(m) <- c("ts", "unif", "exp")
  mali[[c]] <- m
  
}
names(mali) <- len
```  
###Empirycznie wyznaczone moce testów
Po uporządkowaniu danych przedstawiają się one następująco.   
Przypomnienie oznaczeń: 

 * **ts**  - rozkład t-studenta  
 * **unif**- rozkład jednostajny
 * **exp** - rozkład wykładniczy
 * **sw**  - test Shapiro-Wilka
 * **li**  - test Lilliefors'a
 * **jb**  - test Jarque-Bera
 * **chi** - test Pearsona
 * **ad**  - test Anderson-Darling'a  


```{r tabele, echo=FALSE}
mali[[1]] %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "bordered"), full_width = FALSE, position = "float_left") %>%
  column_spec(2:6, width = "5em") %>%
  add_header_above(c(" ",  "wielkość próbki- 10" = 5))

mali[[2]] %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "bordered"), full_width = FALSE, position = "float_right") %>%
  column_spec(2:6, width = "5em") %>%
  add_header_above(c(" ",  "wielkość próbki- 20" = 5))

mali[[3]] %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "bordered"), full_width = FALSE, position = "float_left") %>%
  column_spec(2:6, width = "5em") %>%
  add_header_above(c(" ",  "wielkość próbki- 50" = 5))

mali[[4]] %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "bordered"), full_width = FALSE, position = "right") %>%
  column_spec(2:6, width = "5em") %>%
  add_header_above(c(" ",  "wielkość próbki- 70" = 5))

mali[[5]] %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "bordered"), full_width = FALSE, position = "float_left") %>%
  column_spec(2:6, width = "5em") %>%
  add_header_above(c(" ",  "wielkość próbki- 100" = 5))

mali[[6]] %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "bordered"), full_width = FALSE, position = "right") %>%
  column_spec(2:6, width = "5em") %>%
  add_header_above(c(" ",  "wielkość próbki- 200" = 5))
```    
Powyższe tabele prezentują p-value w zależności poszczególnych czynników.  
Poniżej wizualizacja powyższych wyników na wykresach
```{r wykresy, include=FALSE}
df_pomoc <- as_tibble(df_pomoc)
df_pomoc2 <- cbind(df_pomoc[,-length(df_pomoc)] < alpha, "length" = df_pomoc[,length(df_pomoc)])

df_pomoc3 <- df_pomoc2 %>%
  group_by(length) %>%
  summarise_all(funs(mean))

charts <- list(0, 0, 0, 0)

for (x in 1:length(len))
{
  aaa <- df_pomoc3[which(df_pomoc3$length == len[x]),-1]
  
  aa <- as_tibble(melt(aaa))
  aa <- aa %>%
    separate(variable, c("test", "dist"))
  
  a <- aa %>%
    ggplot(aes(x = dist, y = value, fill = test)) + 
    geom_bar(stat="identity", position = position_dodge()) + 
    coord_flip()+
    geom_text(aes(y = value + 0.09, label = value), size = 4.5, position = position_dodge(0.9), hjust = 1, color = "black") +
    scale_fill_brewer(palette="Paired") +
    labs(title = paste0("Długość próbki: ", len[x]))
  
  charts[[x]] <- a
}
```
```{r echo=FALSE, fig.align="center"}
p1 <- charts[[1]]
p2 <- charts[[2]]
p3 <- charts[[3]]
p4 <- charts[[4]]
p5 <- charts[[5]]
p6 <- charts[[6]]
p1
p2
p3
p4
p5
p6
```
czas kompilacji
```{r echo=FALSE}
Sys.time() - now
```





